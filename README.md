# ğŸ¤– Arabic Question Answering System using AraBART

## ğŸ“‹ Overview
This project implements an Arabic Question Answering (QA) system using the AraBART model fine-tuned on the ARCD (Arabic Reading Comprehension Dataset). The system can extract answers from given Arabic text contexts based on questions posed in Arabic.

## ğŸ—‚ï¸ Project Structure
```
Omar-YYoussef-QA_arabert_finetune/
â”œâ”€â”€ QA_arabert_finetune_code.ipynb    # Training notebook
â”œâ”€â”€ main.py                           # Main application script
â””â”€â”€ model.py                          # Model implementation
```

## âœ¨ Features
- ğŸ” Fine-tuned AraBART model for Arabic question answering
- ğŸ’¡ Support for context-based question answering
- ğŸš€ Easy-to-use pipeline interface
- ğŸ““ Jupyter notebook for model training
- ğŸ§© Modular code structure

## ğŸ› ï¸ Installation

### ğŸ“‹ Prerequisites
- Python 3.10 or higher
- PyTorch
- Transformers
- Datasets
- NumPy
- Pandas

### ğŸš€ Setup
1. Clone the repository:
```bash
git clone [repository-url]
cd Omar-YYoussef-QA_arabert_finetune
```

2. Install required packages:
```bash
pip install torch transformers datasets numpy pandas
```

## ğŸ“– Usage

### ğŸ¤– Using the Pre-trained Model
```python
from model import answer_question, qa_pipeline

# Define your context and question in Arabic
context = "Your Arabic context here"
question = "Your Arabic question here"

# Get the answer
answer = answer_question(qa_pipeline, context, question)
print(f"Answer: {answer}")
```

### ğŸƒâ€â™‚ï¸ Training the Model
The training process is documented in `QA_arabert_finetune_code.ipynb`. The notebook includes:
- ğŸ”„ Data preprocessing
- âš™ï¸ Model configuration
- ğŸ› ï¸ Training pipeline setup
- ğŸš€ Training execution
- ğŸ“Š Model evaluation

## ğŸ” Model Details

### ğŸ—ï¸ Architecture
- Base Model: BERT-base-arabert
- Fine-tuned on: ARCD dataset
- Task: Extractive Question Answering

### âš™ï¸ Training Parameters
- ğŸ“ˆ Learning Rate: 2e-4
- ğŸ“¦ Batch Size: 8
- ğŸ”„ Epochs: 3
- ğŸ› ï¸ Optimizer: AdamW
- âš–ï¸ Weight Decay: 0.02
- ğŸŒ¡ï¸ Warmup Ratio: 0.1

### ğŸ“Š Evaluation Metrics
Below are the comparative performance metrics for different Arabic language models:

| Model        | ROUGE-1 | ROUGE-2 | ROUGE-L | WER    | BLEU   |
|-------------|---------|---------|---------|---------|---------|
| ArabianGpt01| 0.8464  | 0.7562  | 0.8443  | 0.3190  | 0.6353  |
| AraBert     | 0.8415  | 0.7537  | 0.8391  | 0.2765  | 0.6101  |
| DistilBert  | 0.2625  | 0.1117  | 0.2492  | 1.0226  | 0.0240  |

Key observations:
- ğŸ† ArabianGpt01 shows the best overall performance across ROUGE metrics
- ğŸ¥ˆ AraBert performs very similarly to ArabianGpt01
- ğŸ“‰ DistilBert shows significantly lower performance across all metrics except WER
- ğŸ“ˆ Both ArabianGpt01 and AraBert achieve strong ROUGE-1 scores around 0.84

## ğŸ“ Files Description

### ğŸ““ QA_arabert_finetune_code.ipynb
- Contains the complete training pipeline
- Includes data preprocessing steps
- Model training configuration
- Training execution code
- Evaluation metrics

### ğŸ¯ main.py
- Entry point for using the trained model
- Provides simple interface for question answering
- Example usage implementation

### âš™ï¸ model.py
- Model loading and initialization
- Question answering pipeline implementation
- Utility functions for text processing

## ğŸ“ˆ Performance
The model is trained on the ARCD dataset with the following metrics:
- ğŸ“‰ Training Loss: Converges to ~0.95
- ğŸ“Š Validation Loss: ~2.8

## âš ï¸ Limitations
- Works best with Modern Standard Arabic (MSA)
- Context length is limited to model's maximum sequence length
- Requires well-formed Arabic text input

## ğŸ¤ Contributing
Contributions are welcome! Please feel free to submit a Pull Request.


## ğŸ™ Acknowledgments
- ğŸŒŸ AraBART model developers
- ğŸ“š ARCD dataset creators
- ğŸ”§ Hugging Face Transformers library
