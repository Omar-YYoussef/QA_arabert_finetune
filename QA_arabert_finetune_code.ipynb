{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-13T06:53:17.599132Z","iopub.execute_input":"2024-05-13T06:53:17.599785Z","iopub.status.idle":"2024-05-13T06:53:17.953197Z","shell.execute_reply.started":"2024-05-13T06:53:17.599749Z","shell.execute_reply":"2024-05-13T06:53:17.952411Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import DefaultDataCollator\nfrom datasets import load_dataset, Dataset, DatasetDict, concatenate_datasets\nfrom transformers import AutoTokenizer, AutoModelForQuestionAnswering, AutoModelForCausalLM, AutoModelForSeq2SeqLM\nfrom transformers import TrainingArguments, Trainer","metadata":{"execution":{"iopub.status.busy":"2024-05-13T06:53:19.597086Z","iopub.execute_input":"2024-05-13T06:53:19.597878Z","iopub.status.idle":"2024-05-13T06:53:36.218836Z","shell.execute_reply.started":"2024-05-13T06:53:19.597844Z","shell.execute_reply":"2024-05-13T06:53:36.218041Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-05-13 06:53:26.720659: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-13 06:53:26.720756: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-13 06:53:26.843365: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"code","source":"dataset = load_dataset(\"arcd\")","metadata":{"execution":{"iopub.status.busy":"2024-05-13T06:53:59.027353Z","iopub.execute_input":"2024-05-13T06:53:59.028702Z","iopub.status.idle":"2024-05-13T06:54:02.722333Z","shell.execute_reply.started":"2024-05-13T06:53:59.028658Z","shell.execute_reply":"2024-05-13T06:54:02.721350Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/8.53k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f6b962af34a44d7bee43e674b86f8a0"}},"metadata":{}},{"name":"stderr","text":"Downloading data: 100%|██████████| 174k/174k [00:00<00:00, 977kB/s]\nDownloading data: 100%|██████████| 192k/192k [00:00<00:00, 1.79MB/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/693 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a26a4f69d5b4ebbad76c187b664b561"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/702 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5fdc3223af24645b2580180ba797d46"}},"metadata":{}}]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2024-05-13T05:54:06.628768Z","iopub.execute_input":"2024-05-13T05:54:06.629519Z","iopub.status.idle":"2024-05-13T05:54:06.636025Z","shell.execute_reply.started":"2024-05-13T05:54:06.629485Z","shell.execute_reply":"2024-05-13T05:54:06.635096Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'title', 'context', 'question', 'answers'],\n        num_rows: 693\n    })\n    validation: Dataset({\n        features: ['id', 'title', 'context', 'question', 'answers'],\n        num_rows: 702\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"# Extract the train and validation datasets\ntrain_dataset = dataset['train']\nval_dataset = dataset['validation']\n\n# Select the first 150 rows for validation\nnew_val_dataset = val_dataset.select(range(200))\n\n# Select the remaining rows for training\nremaining_val_dataset = val_dataset.select(range(200, len(val_dataset)))\n\n\nnew_train_dataset = concatenate_datasets([train_dataset, remaining_val_dataset])\n\n# Create a new DatasetDict with the updated splits\ndataset = DatasetDict({\n    'train': new_train_dataset,\n    'validation': new_val_dataset\n})\n\n# Print the information of the new DatasetDict\nprint(dataset)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T06:54:05.550798Z","iopub.execute_input":"2024-05-13T06:54:05.551499Z","iopub.status.idle":"2024-05-13T06:54:05.570862Z","shell.execute_reply.started":"2024-05-13T06:54:05.551467Z","shell.execute_reply":"2024-05-13T06:54:05.569989Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'title', 'context', 'question', 'answers'],\n        num_rows: 1195\n    })\n    validation: Dataset({\n        features: ['id', 'title', 'context', 'question', 'answers'],\n        num_rows: 200\n    })\n})\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset = dataset.remove_columns([\"title\",\"id\"])","metadata":{"execution":{"iopub.status.busy":"2024-05-13T06:54:08.443700Z","iopub.execute_input":"2024-05-13T06:54:08.444059Z","iopub.status.idle":"2024-05-13T06:54:08.455350Z","shell.execute_reply.started":"2024-05-13T06:54:08.444030Z","shell.execute_reply":"2024-05-13T06:54:08.454331Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2024-05-13T05:54:20.283848Z","iopub.execute_input":"2024-05-13T05:54:20.284637Z","iopub.status.idle":"2024-05-13T05:54:20.290388Z","shell.execute_reply.started":"2024-05-13T05:54:20.284603Z","shell.execute_reply":"2024-05-13T05:54:20.289474Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['context', 'question', 'answers'],\n        num_rows: 1245\n    })\n    validation: Dataset({\n        features: ['context', 'question', 'answers'],\n        num_rows: 150\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"def preprocess_function(examples):\n    questions = [q.strip() for q in examples[\"question\"]]\n    inputs = tokenizer(\n        questions,\n        examples[\"context\"],\n        max_length=384,\n        truncation=\"only_second\",\n        return_offsets_mapping=True,\n        padding=\"longest\",\n    )\n\n    offset_mapping = inputs.pop(\"offset_mapping\")\n    answers = examples[\"answers\"]\n    start_positions = []\n    end_positions = []\n\n    for i, offset in enumerate(offset_mapping):\n        answer = answers[i]\n        start_char = answer[\"answer_start\"][0] if answer[\"answer_start\"] else None\n        end_char = start_char + len(answer[\"text\"][0]) if start_char is not None else None\n        sequence_ids = inputs.sequence_ids(i) if inputs.sequence_ids(i) else []\n\n        if not start_char or not end_char or not sequence_ids:\n            # Handle cases where start_char, end_char, or sequence_ids are empty\n            start_positions.append(0)\n            end_positions.append(0)\n            continue  # Move to the next iteration\n\n        idx = 0\n        while idx < len(sequence_ids) and sequence_ids[idx] != 1:\n            idx += 1\n        context_start = idx\n\n        while idx < len(sequence_ids) and sequence_ids[idx] == 1:\n            idx += 1\n        context_end = idx - 1\n\n        if context_start >= len(offset) or context_end >= len(offset):\n            # Handle cases where context indices exceed offset_mapping length\n            start_positions.append(0)\n            end_positions.append(0)\n            continue  # Move to the next iteration\n\n        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n            start_positions.append(0)\n            end_positions.append(0)\n        else:\n            idx = context_start\n            while idx <= context_end and offset[idx][0] <= start_char:\n                idx += 1\n            start_positions.append(idx - 1)\n\n            idx = context_end\n            while idx >= context_start and offset[idx][1] >= end_char:\n                idx -= 1\n            end_positions.append(idx + 1)\n\n    inputs[\"start_positions\"] = start_positions\n    inputs[\"end_positions\"] = end_positions\n    return inputs\n\ntokenizer = AutoTokenizer.from_pretrained(\"aubmindlab/bert-base-arabert\")\nencoded_dataset = dataset.map(preprocess_function, batched=True, remove_columns=dataset[\"train\"].column_names)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T06:54:11.255266Z","iopub.execute_input":"2024-05-13T06:54:11.256136Z","iopub.status.idle":"2024-05-13T06:54:13.602986Z","shell.execute_reply.started":"2024-05-13T06:54:11.256094Z","shell.execute_reply":"2024-05-13T06:54:13.602098Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/637 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e4dba13e0a5400a9973c00909aaa1a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/578 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5d99ffac2754b948c7ad49c4f8dc215"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/717k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3e68e72a63d4e45b2b16f9a2d99a437"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.26M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee7c3732f9ac4daca21b51077bcda3c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"274fc0ef203c411b874c53ae0cf39bfb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1195 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9335c1c1261a4d749932a35fdca6cbca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/200 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0e2246eb68848eb800350e494f2a44f"}},"metadata":{}}]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"train_params = TrainingArguments(\n    # Learning algorithms parameters\n    optim = \"adamw_hf\",\n    learning_rate=2e-4,  # Use a smaller learning rate\n    weight_decay=0.02,\n    lr_scheduler_type='linear',\n    warmup_ratio=0.1,\n    output_dir = 'QA_FineTuned_Arabertr',\n    \n    evaluation_strategy=\"steps\",\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    num_train_epochs=3,  # Increase the number of epochs\n    logging_steps=10,\n    save_steps=50,\n    seed=42,\n    # Enable early stopping\n    load_best_model_at_end=True,\n    metric_for_best_model=\"eval_loss\",\n    greater_is_better=False,\n    push_to_hub=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T06:54:17.109931Z","iopub.execute_input":"2024-05-13T06:54:17.110641Z","iopub.status.idle":"2024-05-13T06:54:17.217909Z","shell.execute_reply.started":"2024-05-13T06:54:17.110610Z","shell.execute_reply":"2024-05-13T06:54:17.217010Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForQuestionAnswering.from_pretrained(\"aubmindlab/bert-base-arabert\")","metadata":{"execution":{"iopub.status.busy":"2024-05-13T06:54:20.652512Z","iopub.execute_input":"2024-05-13T06:54:20.653359Z","iopub.status.idle":"2024-05-13T06:54:23.881752Z","shell.execute_reply.started":"2024-05-13T06:54:20.653323Z","shell.execute_reply":"2024-05-13T06:54:23.880980Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/543M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"326699bd19604a5dbfe4600c593a9890"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at aubmindlab/bert-base-arabert and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer = Trainer(\n    model,\n    train_params,\n    train_dataset=encoded_dataset[\"train\"],\n    eval_dataset=encoded_dataset[\"validation\"],\n    tokenizer=tokenizer,\n)\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-05-13T06:54:25.976792Z","iopub.execute_input":"2024-05-13T06:54:25.977154Z","iopub.status.idle":"2024-05-13T06:59:04.585714Z","shell.execute_reply.started":"2024-05-13T06:54:25.977124Z","shell.execute_reply":"2024-05-13T06:59:04.584668Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240513_065437-4z6de7xr</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/hehe595/huggingface/runs/4z6de7xr' target=\"_blank\">youthful-rain-54</a></strong> to <a href='https://wandb.ai/hehe595/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/hehe595/huggingface' target=\"_blank\">https://wandb.ai/hehe595/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/hehe595/huggingface/runs/4z6de7xr' target=\"_blank\">https://wandb.ai/hehe595/huggingface/runs/4z6de7xr</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='225' max='225' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [225/225 04:07, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>5.518000</td>\n      <td>4.357257</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>4.254000</td>\n      <td>3.805361</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>3.991500</td>\n      <td>3.578841</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>3.836000</td>\n      <td>3.405401</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>3.673300</td>\n      <td>3.250558</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>3.442500</td>\n      <td>3.088195</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>3.291700</td>\n      <td>2.993389</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>2.962200</td>\n      <td>3.002911</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>2.322800</td>\n      <td>3.119015</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>2.400400</td>\n      <td>2.861346</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>2.394600</td>\n      <td>2.898267</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>2.310800</td>\n      <td>2.771058</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>2.377800</td>\n      <td>2.706213</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>2.333500</td>\n      <td>2.991603</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>2.427300</td>\n      <td>2.671340</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>1.416500</td>\n      <td>2.800321</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>1.148800</td>\n      <td>2.795913</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>1.204400</td>\n      <td>3.131092</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>1.271500</td>\n      <td>2.831911</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>1.130900</td>\n      <td>2.804776</td>\n    </tr>\n    <tr>\n      <td>210</td>\n      <td>1.342100</td>\n      <td>2.815797</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>0.956700</td>\n      <td>2.835749</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=225, training_loss=2.514185447692871, metrics={'train_runtime': 277.3149, 'train_samples_per_second': 12.928, 'train_steps_per_second': 0.811, 'total_flos': 702561654673920.0, 'train_loss': 2.514185447692871, 'epoch': 3.0})"},"metadata":{}}]}]}